{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('trainms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['work_interfere']=df['work_interfere'].fillna(\"Maybe\")\n",
    "df['self_employed']=df['self_employed'].fillna(\"Dont Know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.Gender\n",
    "temp = temp.replace(to_replace=[\"A little about you\",\"something kinda male?\",\"Enby\",\"fluid\",\"Genderqueer\",\"Trans-female\",\"Nah\",\"Androgyne\",\"Agender\",\"male leaning androgynous\",\"Trans woman\",\"Neuter\",\"Female (trans)\",\"queer\",\"non-binary\"],value=\"T\")\n",
    "temp = temp.replace([\"Female\",\"female\",\"Cis Female\",\"F\",\"Woman\",\"f\",\"Femake\",\"Female \",\"woman\",\"cis-female/femme\",\"Female (cis)\"],'F')\n",
    "temp = temp.replace([\"M\",\"Male\",\"male\",\"m\",\"Male-ish\",\"maile\",\"Cis Male\",\"Mal\",\"Male \",\"Make\",\"Guy (-ish) ^_^\",\"Man\",\"msle\",\"Mail\",\"cis male\"],'M')\n",
    "temp.unique()\n",
    "df.Gender = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_columns = ['state','comments','s.no','Timestamp']+['supervisor','coworkers','Country','anonymity','self_employed'] #+['Country','supervisor','coworkers','phys_health_interview','anonymity','self_employed','remote_work','tech_company','obs_consequence','phys_health_consequence','seek_help','Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=to_drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'family_history', 'treatment', 'work_interfere',\n",
       "       'no_employees', 'remote_work', 'tech_company', 'benefits',\n",
       "       'care_options', 'wellness_program', 'seek_help', 'leave',\n",
       "       'mental_health_consequence', 'phys_health_consequence',\n",
       "       'mental_health_interview', 'phys_health_interview',\n",
       "       'mental_vs_physical', 'obs_consequence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target = df.pop('treatment')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-25739a54c04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"treatment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# pd.factorize(target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "features = df.apply(le.fit_transform)\n",
    "\n",
    "onc = preprocessing.OneHotEncoder(categorical_features=[1,2])\n",
    "features = onc.fit_transform(features).toarray()\n",
    "\n",
    "labels,uniques = features[\"treatment\"] # pd.factorize(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 2., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 2., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( features, labels, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=0.3, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
    "                               max_depth=4, min_samples_leaf=0.3)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\",max_depth=4,presort=True)\n",
    "clf_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.42857142857143"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_pred = clf_gini.predict(X_train)\n",
    "accuracy_score(y_train,gini_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_pred = clf_entropy.predict(X_train)\n",
    "accuracy_score(y_train,entropy_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_pred = clf_gini.predict(X_test)\n",
    "accuracy_score(y_test,gini_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_pred = clf_entropy.predict(X_test)\n",
    "accuracy_score(y_test,entropy_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, entropy_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "randoms = np.linspace(1, 1000, 100, endpoint=True,dtype=int)\n",
    "x_train,x_test = X_train,X_test\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for random in randoms:\n",
    "    dt = DecisionTreeClassifier(random_state=random)\n",
    "    dt.fit(x_train, y_train)\n",
    "    train_pred = dt.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(randoms, train_results, \"b\", label=\"Train AUC\")\n",
    "line2, = plt.plot(randoms, test_results, \"r\", label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"AUC score\")\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "print(min_samples_leafs)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    dt = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "    dt.fit(x_train, y_train)\n",
    "    train_pred = dt.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "    \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(min_samples_leafs, train_results, \"b\", label=\"Train AUC\")\n",
    "line2, = plt.plot(min_samples_leafs, test_results, \"r\", label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"AUC score\")\n",
    "plt.xlabel(\"min samples leaf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_features = list(range(1,X_train.shape[1]))\n",
    "x_train,x_test = X_train,X_test\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_feature in max_features:\n",
    "    dt = DecisionTreeClassifier(max_features=max_feature)\n",
    "    dt.fit(x_train, y_train)\n",
    "    train_pred = dt.predict(x_train)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_features, train_results, \"b\", label=\"Train AUC\")\n",
    "line2, = plt.plot(max_features, test_results, \"r\", label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"AUC score\")\n",
    "plt.xlabel(\"Max Featues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('testms.csv')\n",
    "temp = test.Age\n",
    "temp = temp.replace(to_replace=-1,value=22)\n",
    "test.Age = temp\n",
    "\n",
    "test['work_interfere']=test['work_interfere'].fillna(\"Maybe\")\n",
    "test['self_employed']=test['self_employed'].fillna(\"Dont Know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate test gender\n",
    "temp = test.Gender\n",
    "temp = temp.replace(to_replace=[\"Male\",\"male\",\"m\",\"Malr\",\"Male \",\"Cis Man\"],value='M')\n",
    "temp = temp.replace(to_replace=[\"female\",\"F\",\"Female\",\"Woman\",\"femail\",\"f\"],value='F')\n",
    "temp = temp.replace(to_replace=[\"p\",\"Female (trans)\",\"ostensibly male, unsure what that really means\"],value='T')\n",
    "test.Gender = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict testing data\n",
    "# col = to_drop_columns\n",
    "# col.remove('treatment')\n",
    "test_features = test.drop(columns=to_drop_columns)\n",
    "le = preprocessing.LabelEncoder()\n",
    "test_features = test_features.apply(le.fit_transform)\n",
    "\n",
    "pred = clf_entropy.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission generation\n",
    "index = [str(i) for i in range(1,len(pred)+1)]\n",
    "values = ['Yes' if val==0 else 'No' for i,val in enumerate(pred)]\n",
    "submission_result = pd.DataFrame(values, index=index,columns=['treatment'])\n",
    "submission_result.index.name = \"s.no\"\n",
    "\n",
    "file_name=\"submission.csv\"\n",
    "submission_result.to_csv(file_name, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
